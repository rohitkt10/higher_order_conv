{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, h5py, pandas as pd, sys\n",
    "import numpy as np\n",
    "srcpath = os.path.join(os.getcwd(), '..')\n",
    "sys.path.append(srcpath)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "\n",
    "from paramiko import SSHClient\n",
    "from scp import SCPClient\n",
    "\n",
    "from pairwise_conv_1d import PairwiseConv1D, PairwiseFromStdConv1D\n",
    "from nearest_neighbor_conv_1d import NearestNeighborConv1D, NearestNeighborFromStdConv1D\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up ssh and scp connection \n",
    "username, hostname = os.getenv('BAMDEV1').split(\"@\")\n",
    "ssh = SSHClient()\n",
    "ssh.load_system_host_keys()\n",
    "ssh.connect(hostname=hostname, username=username)\n",
    "remotehome = ssh.exec_command(\"echo $HOME\")[1].readlines()[0].strip()\n",
    "scp = SCPClient(ssh.get_transport())\n",
    "REMOTEDATADIR = os.path.join(remotehome, \"projects/higher_order_convolutions\", 'data', 'deepbind_encode_chipseq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data ...\n",
      "Loading data ...\n"
     ]
    }
   ],
   "source": [
    "# download data for a particular tfid\n",
    "tfid = \"POLR2A_K562_Pol2_HudsonAlpha\"\n",
    "print(\"Downloading data ...\")\n",
    "if not os.path.exists(\"data.h5\"):\n",
    "    scp.get(remote_path=os.path.join(REMOTEDATADIR, tfid, 'data.h5'))\n",
    "print(\"Loading data ...\")\n",
    "data = h5py.File('data.h5', 'r')\n",
    "x_train = data['X_train'][:]\n",
    "y_train = data['Y_train'][:]\n",
    "x_test = data['X_test'][:]\n",
    "y_test = data['Y_test'][:]\n",
    "if y_train.ndim == 1:\n",
    "    y_train = y_train[:, None]\n",
    "if y_test.ndim == 1:\n",
    "    y_test = y_test[:, None]\n",
    "data.close()\n",
    "!rm data.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 50, 15) [<tf.Tensor: shape=(), dtype=float32, numpy=6.1221967e-06>]\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.normal((2, 50, 4))\n",
    "diag_regularizer = tfk.regularizers.l2(1e-6)\n",
    "conv_kwargs = {'filters':15, 'kernel_size':9, 'padding':'same', 'kernel_regularizer':diag_regularizer}\n",
    "stdconv = tfk.layers.Conv1D(**conv_kwargs)\n",
    "y = stdconv(x)\n",
    "print(y.shape, stdconv.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offdiag_regularizer = tfk.regularizers.l1(1e-2)\n",
    "pconv = PairwiseFromStdConv1D(stdconv=stdconv, offdiag_regularizer=offdiag_regularizer)\n",
    "y = pconv(x)\n",
    "print(y.shape, pconv.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offdiag_regularizer = tfk.regularizers.l1(1e-2)\n",
    "nnconv = NearestNeighborFromStdConv1D(stdconv=stdconv, offdiag_regularizer=offdiag_regularizer)\n",
    "y = nnconv(x)\n",
    "print(y.shape, nnconv.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pconv.diag_kernel.shape, pconv.offdiag_kernel.shape)\n",
    "print(nnconv.diag_kernel.shape, nnconv.offdiag_kernel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_type_dict = {'standard':tfk.layers.Conv1D, 'pairwise':PairwiseConv1D, 'nearest_neighbor':NearestNeighborConv1D}\n",
    "\n",
    "def cnn25_model(conv_type='standard', kernel_regularizer=tfk.regularizer.l2(1e-6)):\n",
    "    x = tfk.layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 1st conv layer \n",
    "    assert conv_type in conv_type_dict\n",
    "    Conv1D = conv_type_dict[conv_type]\n",
    "    y = Conv1D(filters=32, kernel_size=19, use_bias=True, padding='same', kernel_regularizer=kernel_regularizer)(x)\n",
    "    y = tfk.layers.BatchNormalization()(y)\n",
    "    y = tfk.layers.Activation('relu')(y)\n",
    "    y = tfk.layers.MaxPool1D(pool_size=25)\n",
    "\n",
    "# create keras model\n",
    "return keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(input_shape, num_labels, activation='relu', pool_size=[25, 4], \n",
    "          units=[32, 128, 512], dropout=[0.2, 0.2, 0.5], \n",
    "          bn=[True, True, True], l2=None):\n",
    "  \n",
    "    # l2 regularization\n",
    "    if l2 is not None:\n",
    "        l2 = keras.regularizers.l2(l2)\n",
    "\n",
    "    # input layer\n",
    "    inputs = keras.layers.Input(shape=input_shape)\n",
    "\n",
    "    # layer 1 - convolution\n",
    "    use_bias = []\n",
    "    for status in bn:\n",
    "        if status:\n",
    "            use_bias.append(True)\n",
    "        else:\n",
    "            use_bias.append(False)\n",
    "\n",
    "    nn = keras.layers.Conv1D(filters=units[0],\n",
    "                            kernel_size=19,\n",
    "                            strides=1,\n",
    "                            activation=None,\n",
    "                            use_bias=use_bias[0],\n",
    "                            padding='same',\n",
    "                            kernel_regularizer=l2, \n",
    "                            )(inputs)\n",
    "    if bn[0]:\n",
    "        nn = keras.layers.BatchNormalization()(nn)\n",
    "    nn = keras.layers.Activation(activation)(nn)\n",
    "    nn = keras.layers.MaxPool1D(pool_size=pool_size[0])(nn)\n",
    "    nn = keras.layers.Dropout(dropout[0])(nn)\n",
    "\n",
    "    # layer 2 - convolution\n",
    "    nn = keras.layers.Conv1D(filters=units[1],\n",
    "                            kernel_size=7,\n",
    "                            strides=1,\n",
    "                            activation=None,\n",
    "                            use_bias=use_bias[1],\n",
    "                            padding='same',\n",
    "                            kernel_regularizer=l2, \n",
    "                            )(nn)  \n",
    "    if bn[1]:        \n",
    "    nn = keras.layers.BatchNormalization()(nn)\n",
    "    nn = keras.layers.Activation('relu')(nn)\n",
    "    nn = keras.layers.MaxPool1D(pool_size=pool_size[1])(nn)\n",
    "    nn = keras.layers.Dropout(dropout[1])(nn)\n",
    "\n",
    "    # layer 3 - Fully-connected \n",
    "    nn = keras.layers.Flatten()(nn)\n",
    "    nn = keras.layers.Dense(units[2],\n",
    "    activation=None,\n",
    "    use_bias=use_bias[2],\n",
    "    kernel_regularizer=l2, \n",
    "    )(nn)      \n",
    "    if bn[2]:\n",
    "    nn = keras.layers.BatchNormalization()(nn)\n",
    "    nn = keras.layers.Activation('relu')(nn)\n",
    "    nn = keras.layers.Dropout(dropout[2])(nn)\n",
    "\n",
    "    # Output layer\n",
    "    logits = keras.layers.Dense(num_labels, activation='linear', use_bias=True)(nn)\n",
    "    outputs = keras.layers.Activation('sigmoid')(logits)\n",
    "\n",
    "    # create keras model\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
