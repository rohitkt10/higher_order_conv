{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, os, h5py, pandas as pd\n",
    "np.set_printoptions(suppress=True)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tfomics import tfomics \n",
    "from tfomics.tfomics import moana, impress, explain\n",
    "import logomaker\n",
    "from logomaker import Logo\n",
    "\n",
    "from paramiko import SSHClient\n",
    "from scp import SCPClient\n",
    "\n",
    "from pairwise_conv_1d import PairwiseConv1D, PairwiseFromStdConv1D\n",
    "from nearest_neighbor_conv_1d import NearestNeighborConv1D, NearestNeighborFromStdConv1D\n",
    "from ho_regularizer import HigherOrderKernelRegularizer\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "tfk.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_compliment = True\n",
    "data_path = os.path.join('./../../../genomics_datasets/exponential_activations')\n",
    "filepath = os.path.join(data_path, 'IRF1_400_h3k27ac.h5')\n",
    "with h5py.File(filepath, 'r') as dataset:\n",
    "    x_train = np.array(dataset['X_train']).astype(np.float32)\n",
    "    y_train = np.array(dataset['Y_train']).astype(np.float32)\n",
    "    x_valid = np.array(dataset['X_valid']).astype(np.float32)\n",
    "    y_valid = np.array(dataset['Y_valid']).astype(np.int32)\n",
    "    x_test = np.array(dataset['X_test']).astype(np.float32)\n",
    "    y_test = np.array(dataset['Y_test']).astype(np.int32)\n",
    "\n",
    "x_train = np.squeeze(x_train).transpose([0,2,1])\n",
    "x_valid = np.squeeze(x_valid).transpose([0,2,1])\n",
    "x_test = np.squeeze(x_test).transpose([0,2,1])\n",
    "n = x_train.shape[0]\n",
    "\n",
    "if reverse_compliment:\n",
    "    x_train_rc = x_train[:,::-1,:][:,:,::-1]\n",
    "    x_valid_rc = x_valid[:,::-1,:][:,:,::-1]\n",
    "    x_test_rc = x_test[:,::-1,:][:,:,::-1]\n",
    "\n",
    "    x_train = np.vstack([x_train, x_train_rc])\n",
    "    x_valid = np.vstack([x_valid, x_valid_rc])\n",
    "    x_test = np.vstack([x_test, x_test_rc])\n",
    "\n",
    "    y_train = np.vstack([y_train, y_train])\n",
    "    y_valid = np.vstack([y_valid, y_valid])\n",
    "    y_test = np.vstack([y_test, y_test])\n",
    "\n",
    "# create tensorflow dataset\n",
    "trainset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "validset = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "sampleset = tf.data.Dataset.from_tensor_slices((x_valid[:2], y_valid[:2]))\n",
    "\n",
    "N, L, A = x_test.shape\n",
    "num_labels = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-9e459e4fda95>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-9e459e4fda95>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    f get_model(input_shape, first_layer_conv, name='model', first_layer_activation='relu'):\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "f get_model(input_shape, first_layer_conv, name='model', first_layer_activation='relu'):\n",
    "    x = tfk.layers.Input(shape=input_shape, name='input')\n",
    "    y = first_layer_conv(x)\n",
    "    if first_layer_conv.use_bias:\n",
    "        y = tfk.layers.BatchNormalization()(y)\n",
    "    y = tfk.layers.Activation(first_layer_activation, name=first_layer_activation)(y)\n",
    "    y = tfk.layers.MaxPool1D(pool_size=25)(y)\n",
    "    y = tfk.layers.Dropout(0.1)(y)\n",
    "    \n",
    "    # layer 2 - convolution\n",
    "    l2 = tfk.regularizers.l2(1e-4)\n",
    "    y = tfk.layers.Conv1D(filters=48,kernel_size=7,strides=1,padding='same',kernel_regularizer=l2, )(y)        \n",
    "    y = tfk.layers.Activation('relu')(y)\n",
    "    y = tfk.layers.MaxPool1D(pool_size=4)(y)\n",
    "    y = tfk.layers.Dropout(0.1)(y)\n",
    "\n",
    "    # layer 3 - Fully-connected \n",
    "    y = tfk.layers.Flatten()(y)\n",
    "    y = tfk.layers.Dense(96,use_bias=False,kernel_regularizer=l2)(y)      \n",
    "    y = tfk.layers.BatchNormalization()(y)\n",
    "    y = tfk.layers.Activation('relu')(y)\n",
    "    y = tfk.layers.Dropout(0.5)(y)\n",
    "\n",
    "    # Output layer\n",
    "    y = tfk.layers.Dense(1, kernel_initializer='glorot_normal',name='logits')(y)\n",
    "    y = tfk.layers.Activation('sigmoid')(y)\n",
    "\n",
    "    # create keras model\n",
    "    model = tfk.Model(inputs=x, outputs=y, name=name)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
